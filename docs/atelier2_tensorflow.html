<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Introduction à Tensorflow</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 54px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 59px;
  margin-top: -59px;
}

.section h2 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h3 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h4 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h5 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h6 {
  padding-top: 59px;
  margin-top: -59px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">FinistR 2018</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    accueil
  </a>
</li>
<li>
  <a href="https://github.com/StateOfTheR/finistR2018">
    <span class="fa fa-github"></span>
     
    dépôt github
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-refresh"></span>
     
    Webscraping
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="atelier1_webscraping_intro.html">Introduction</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="atelier1_webscraping_simple.html">Un exemple simple</a>
    </li>
    <li>
      <a href="atelier1_webscraping_genealogie.html">Généalogie mathématique</a>
    </li>
    <li>
      <a href="atelier1_webscraping_tripadvisor.html">Trip advisor</a>
    </li>
    <li>
      <a href="atelier1_webscraping_googlefight.html">Occurrences Google</a>
    </li>
    <li>
      <a href="atelier1_webscraping_youtube.html">Youtube, MSN meteo</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-wheelchair-alt"></span>
     
    Optimisation et accélération
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="atelier2_introduction.html">Introduction</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="atelier2_background_optim.html">Outils d'optimisation standard</a>
    </li>
    <li>
      <a href="atelier2_rgpu.html">R et GPU</a>
    </li>
    <li>
      <a href="atelier2_tensorflow.html">TensorFlow</a>
    </li>
    <li>
      <a href="atelier2_greta.html">Greta</a>
    </li>
    <li>
      <a href="atelier2_rcpp_modules.html">Modules Rcpp</a>
    </li>
    <li>
      <a href="atelier2_julia.html">Julia</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-thumbs-o-up"></span>
     
    Bonnes pratiques
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Introduction</li>
    <li class="divider"></li>
    <li>
      <a href="atelier3_git.html">Versioning with git(hub)</a>
    </li>
    <li>
      <a href="atelier3_makefile_tuto.html">Understanding Makefiles</a>
    </li>
    <li>
      <a href="atelier3_package_creation.html">Packages: création, développement, tests</a>
    </li>
    <li>
      <a href="atelier3_advancedrmd.html">Production de documents</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Introduction à Tensorflow</h1>

</div>


<div id="tensorflow-en-quelques-mots" class="section level2">
<h2>Tensorflow en quelques mots</h2>
<p>TensorFlow est essentiellement connu comme l’optimiseur permettant d’ajuster des modèles d’apprentissage profond. Cet ensemble de codes a été développé par Google. Dans cette introduction, on s’intéresse au principe de fonctionnement de TensorFlow. L’idée est que l’on peut espérer comprendre les principes de base et accéder aux fonctions code afin d’optimiser n’importe quelle autre fonction telle qu’une vraisemblance, des moindres carrés pénalisés, etc…</p>
<p>Pour minimiser une fonction, on a par exemple recourt à un algorithme de descente de gradient plus ou moins complexe (stochastique ou non, contraint ou non). Par défaut, on utilisera sour R la fonction <code>optim</code>. Deux cas se présentent : soit le gradient est calculable à la main et alors on peut le fournir comme argument de la fonction <code>optim</code>, ou alors par défaut ce gradient est approché numériquement. L’approximation numérique du gradient conduit à des temps de calculs élévés.</p>
<p>La puissance de TensorFlow est de faire appel à la différenciation automatique pour calculer le gradient. La différenciation automatique est introduite sur la page Wikipedia correspondante &lt; <a href="https://en.wikipedia.org/wiki/Automatic_differentiation" class="uri">https://en.wikipedia.org/wiki/Automatic_differentiation</a>&gt;. En quelques mots, si <span class="math inline">\(f\)</span> est la fonction d’intéret, la différenciation automatique commence par décomposer cette fonction <span class="math inline">\(f\)</span> en opérations simples telles que des sommes, produits, puissances, exponentielles, etc. On obtient alors la représentation de la fonction <span class="math inline">\(f\)</span> sous forme d’arbre, où les noeuds dont les opérations et les arêtes représentent le flux des données/variables. Par exemple, on peut décomposer la densité de la gaussienne selon le schéma suivant:</p>
<center>
<img src="img/gaussian_tensor_flow.png" alt="Décomposition de la densité d’une gaussienne" width="400" />
</center>
<p>Une fois la fonction encodée sous forme d’arbre composée d’opérations simples, les dérivées partielels sont obtenues par l’application de la Chain Rule (dérivation des fonctions composées). Ces dérivées peuvent être obtenues en remontant l’arbre ou en le descendant, aboutissant ainsi à deux algorithmes: forward et backward.</p>
<p>Cette méthode de calcul des dérivées est connue pour être efficace. C’est ce qui a permis entre autre le développement des méthodes d’apprentissage profond. Nous pouvons espérer utiliser cette puissance au service d’autres problèmes d’optimisation.</p>
<p>Pour cela, il faut revenir au choeur de TensorFlow pour aller chercher les méthodes propres à la différenciation automatique. Il est plus facile d’appeler TensorFlow en python. Mais il est aussi possible d’utiliser TensorFlow en R. Nous proposons des exemples en Pythons et en .</p>
</div>
<div id="minimiser-une-fonction-quelconque-par-tensorflow-sous-r." class="section level2">
<h2>Minimiser une fonction quelconque par <code>TensorFlow</code> sous R.</h2>
<div id="installation-de-tensorflow." class="section level3">
<h3>Installation de TensorFlow.</h3>
<p>TensorFlow doit d’abord être installé sur la machine. Les étapes sont les suivantes. Préalablement au lancement de <code>RStudio</code> il faut</p>
<ul>
<li>Vérifier que <code>python 3.6</code> est installé (ou bien l’installer)</li>
<li>Installer <code>miniconda</code> (<a href="https://conda.io/miniconda.html" class="uri">https://conda.io/miniconda.html</a>)</li>
</ul>
<p>Puis depuis <code>RStudio</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&#39;tensorflow&#39;</span>)
<span class="kw">install_tensorflow</span>()</code></pre></div>
<p>L’opération install_tensorflow() est longue et nécéssite une bonne connectin internet.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tensorflow)</code></pre></div>
</div>
<div id="exemple-1-estimation-dune-regression-lineaire-simple" class="section level3">
<h3>Exemple 1 : Estimation d’une régression linéaire simple</h3>
<p>Cet exemple est issu du site <a href="https://tensorflow.rstudio.com/tensorflow/articles/examples/linear_regression_simple.html" class="uri">https://tensorflow.rstudio.com/tensorflow/articles/examples/linear_regression_simple.html</a>.</p>
<p>On commence par simuler des données.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x_data &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>)
y_data &lt;-<span class="st"> </span>x_data <span class="op">*</span><span class="st"> </span><span class="fl">0.1</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.3</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="fl">0.1</span>)</code></pre></div>
<p>Puis on va décrire la fonction à optimiser dans le language <code>TensorFlow</code>. Tout d’abord nous déclarons les variables qui seront optimisées.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(tf<span class="op">$</span><span class="kw">zeros</span>(<span class="kw">shape</span>(1L)))
b &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(tf<span class="op">$</span><span class="kw">zeros</span>(<span class="kw">shape</span>(1L)))</code></pre></div>
<p><code>a</code> et <code>b</code> sont ainsi définies comme les variables à optimiser. A partir de <code>a</code> et <code>b</code> on définit la fonction à optimiser (ici <code>loss</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span>a <span class="op">*</span><span class="st"> </span>x_data <span class="op">+</span><span class="st"> </span>b
loss &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">reduce_mean</span>((y <span class="op">-</span><span class="st"> </span>y_data) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>)
loss</code></pre></div>
<pre><code>## Tensor(&quot;Mean:0&quot;, shape=(), dtype=float32)</code></pre>
<p>On récupère un objet <code>Tensorflow</code> illisible. On spécifie maintenant la méthode d’optimisation (ici une descente de gradient) qu’on relie ensuite à la fonction <code>loss</code> qui sera minimisée.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">optimizer &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">GradientDescentOptimizer</span>(<span class="fl">0.5</span>)
train &lt;-<span class="st"> </span>optimizer<span class="op">$</span><span class="kw">minimize</span>(loss)</code></pre></div>
<p>A ce stade, rien n’a été calculé, nous avons juste défini les objets <code>TensorFlow</code> nécéssaires à l’exécution. L’algorithme de minisation par descente de gradient s’écrit de la façon suivante:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Launch the graph and initialize the variables.</span>
sess =<span class="st"> </span>tf<span class="op">$</span><span class="kw">Session</span>()
sess<span class="op">$</span><span class="kw">run</span>(tf<span class="op">$</span><span class="kw">global_variables_initializer</span>())
<span class="cf">for</span> (step <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">201</span>) {
  sess<span class="op">$</span><span class="kw">run</span>(train)
  <span class="cf">if</span> (step <span class="op">%%</span><span class="st"> </span><span class="dv">20</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>)
    <span class="kw">cat</span>(step, <span class="st">&quot;-&quot;</span>, sess<span class="op">$</span><span class="kw">run</span>(a), sess<span class="op">$</span><span class="kw">run</span>(b), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
}</code></pre></div>
<pre><code>## 20 - 0.1222981 0.3038565 
## 40 - 0.1145072 0.3079129 
## 60 - 0.1123584 0.3090316 
## 80 - 0.1117658 0.3093401 
## 100 - 0.1116024 0.3094253 
## 120 - 0.1115573 0.3094487 
## 140 - 0.1115449 0.3094552 
## 160 - 0.1115414 0.309457 
## 180 - 0.1115405 0.3094575 
## 200 - 0.1115403 0.3094576</code></pre>
</div>
<div id="exemple-2-calcul-du-mode-dune-loi-gamma." class="section level3">
<h3>Exemple 2 : calcul du mode d’une loi <span class="math inline">\(\Gamma\)</span>.</h3>
<p>On applique la même procédure pour trouver le mode de la densité d’un loi <span class="math inline">\(\Gamma\)</span> de paramètres <span class="math inline">\(\alpha\)</span> et <span class="math inline">\(\beta\)</span>. Ces paramètres sont fixés:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">alpha &lt;-<span class="st"> </span><span class="dv">3</span>
beta &lt;-<span class="st"> </span><span class="dv">6</span></code></pre></div>
<p>On déclare ensuite les objets <code>TensorFlow</code> (constantes, variables), etc…:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># définition des objets tf</span>
x &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(tf<span class="op">$</span><span class="kw">zeros</span>(<span class="kw">shape</span>(1L)))
alpha.tf &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">constant</span>(alpha)
beta.tf  &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">constant</span>(beta)
gamma.func.tf &lt;-<span class="st"> </span><span class="op">-</span><span class="kw">exp</span>(x)<span class="op">^</span>(alpha.tf <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>beta.tf <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(x))</code></pre></div>
<p>Puis la méthode d’optimisation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">optimizer &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">GradientDescentOptimizer</span>(<span class="fl">0.5</span>)
train &lt;-<span class="st"> </span>optimizer<span class="op">$</span><span class="kw">minimize</span>(gamma.func.tf)

<span class="co"># descente de gradient</span>
sess =<span class="st"> </span>tf<span class="op">$</span><span class="kw">Session</span>()
sess<span class="op">$</span><span class="kw">run</span>(tf<span class="op">$</span><span class="kw">global_variables_initializer</span>())
<span class="cf">for</span> (step <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">201</span>) {
  sess<span class="op">$</span><span class="kw">run</span>(train)
  <span class="cf">if</span> (step <span class="op">%%</span><span class="st"> </span><span class="dv">20</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>)
    <span class="kw">cat</span>(step, <span class="st">&quot;-&quot;</span>, sess<span class="op">$</span><span class="kw">run</span>(<span class="kw">exp</span>(x)), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
}</code></pre></div>
<pre><code>## 20 - 0.8944995 
## 40 - 0.7787731 
## 60 - 0.6644896 
## 80 - 0.5669852 
## 100 - 0.494284 
## 120 - 0.4441656 
## 140 - 0.4104501 
## 160 - 0.3876656 
## 180 - 0.372042 
## 200 - 0.3611595</code></pre>
</div>
</div>
<div id="session-interactive" class="section level2">
<h2>Session interactive</h2>
<p>Afin de profiter des interfaces interactives comme <code>Rstudio</code>avec <code>tensorflow</code>, il est possible de lancer une session interactive. Cela permet d’exécuter les opérations sur le graphes ligne par ligne et de ne pas bloquer les noms des variables. On ouvre une session interactive avec <code>tf$InteractiveSession()</code>. Pour éviter les conflits inhérents au fait d’avoir plusieurs sessions ouvertes en même temps, il est important de les fermer à chaque fois.</p>
<p>L’exemple ci-dessous est tiré de <a href="https://tensorflow.rstudio.com/tensorflow/articles/basic_usage.html" class="uri">https://tensorflow.rstudio.com/tensorflow/articles/basic_usage.html</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tensorflow)

sess &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">InteractiveSession</span>()

x &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(<span class="kw">c</span>(<span class="fl">1.0</span>, <span class="fl">2.0</span>))
a &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">constant</span>(<span class="kw">c</span>(<span class="fl">3.0</span>, <span class="fl">3.0</span>))



<span class="co"># Initialize &#39;x&#39; using the run() method of its initializer op.</span>
x<span class="op">$</span>initializer<span class="op">$</span><span class="kw">run</span>()

<span class="co"># Add an op to subtract &#39;a&#39; from &#39;x&#39;.  Run it and print the result</span>
sub &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">subtract</span>(x, a)
<span class="kw">print</span>(sub<span class="op">$</span><span class="kw">eval</span>())</code></pre></div>
<pre><code>## [1] -2 -1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sess<span class="op">$</span><span class="kw">close</span>()</code></pre></div>
<p>Attention ! Les indices des objets de type “Tensor” dans <code>tensorflow</code> sont les même qu’en <code>Python</code> (indicé à partir de 0 et non à partir de 1 comme en <code>R</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sess &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">InteractiveSession</span>()
x &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="fl">2.0</span>, <span class="fl">2.0</span>, <span class="dt">by =</span> <span class="dv">1</span>))
x<span class="op">$</span>initializer<span class="op">$</span><span class="kw">run</span>()
abs_x &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">abs</span>(x)
<span class="kw">print</span>(abs_x<span class="op">$</span><span class="kw">eval</span>())</code></pre></div>
<pre><code>## [1] 2 1 0 1 2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(abs_x[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">eval</span>())</code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(abs_x[[<span class="dv">0</span>]]<span class="op">$</span><span class="kw">eval</span>())</code></pre></div>
<pre><code>## [1] 2</code></pre>
<p>D’autres objets, se présentent sous la forme d’une liste de Tensor. Les listes sont indicées comme en <code>R</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grad_abs &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">gradients</span>(<span class="kw">abs</span>(x), x)
<span class="kw">str</span>(grad_abs)</code></pre></div>
<pre><code>## List of 1
##  $ :Tensor(&quot;gradients_2/Abs_1_grad/mul:0&quot;, shape=(5,), dtype=float32)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(grad_abs[[<span class="dv">1</span>]]<span class="op">$</span><span class="kw">eval</span>())</code></pre></div>
<pre><code>## [1] -1 -1  0  1  1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(grad_abs[[<span class="dv">1</span>]][[<span class="dv">2</span>]]<span class="op">$</span><span class="kw">eval</span>())</code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sess<span class="op">$</span><span class="kw">close</span>()</code></pre></div>
</div>
<div id="tensorboard-visualisation-interactive-de-graphe" class="section level2">
<h2>Tensorboard, visualisation interactive de graphe</h2>
<p><code>tensorboard</code> <a href="https://tensorflow.rstudio.com/tensorflow/articles/howto_summaries_and_tensorboard.html" class="uri">https://tensorflow.rstudio.com/tensorflow/articles/howto_summaries_and_tensorboard.html</a> est un outil de visualisation permettant d’observer de manière interactive les graphes <code>tensorflow</code>. Il est possible de s’en servir pour voir les ètapes de différentiation automatique pour le calcul du gradient d’une fonction. <code>tensorboard</code> lit un log crée lors de l’exécution de la session. Il est possible de créer toute sorte de statistiques résumant le graphe afin de les visualiser.</p>
<div id="exemple-derivee-de-la-densite-dune-loi-gaussienne" class="section level3">
<h3>Exemple : dérivée de la densité d’une loi gaussienne</h3>
<p>La fonction à dériver doit être écrite sous forme de fonction mathématique de base <code>tensorflow</code> :</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gaussian &lt;-<span class="st"> </span><span class="cf">function</span>(x, mu, sig) {
  <span class="dv">1</span>.<span class="op">/</span>(sig <span class="op">*</span><span class="st"> </span>tf<span class="op">$</span><span class="kw">sqrt</span>(<span class="dv">2</span>. <span class="op">*</span><span class="st"> </span>pi )) <span class="op">*</span><span class="st"> </span>tf<span class="op">$</span><span class="kw">exp</span>(<span class="op">-</span>.<span class="dv">5</span> <span class="op">*</span><span class="st"> </span>((x <span class="op">-</span><span class="st"> </span>mu)<span class="op">/</span>sig)<span class="op">**</span><span class="dv">2</span>)
}</code></pre></div>
<p>Il est important de réinitialiser le graphe <code>tensorflow</code>. Celui-ci n’est pas stocké dans les variables d’environnement et vider l’environnement de travail sous <code>Rstudio</code> ne réinitialise pas le graph <code>tensorflow</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tf<span class="op">$</span><span class="kw">reset_default_graph</span>()
mu  &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">constant</span>(<span class="fl">0.0</span>, <span class="dt">name =</span> <span class="st">&quot;mu&quot;</span>)
sig &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">constant</span>(<span class="fl">1.0</span>, <span class="dt">name =</span> <span class="st">&quot;sigma&quot;</span>)
x   &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">placeholder</span>(<span class="dt">dtype =</span> tf<span class="op">$</span>float32, <span class="dt">shape =</span> <span class="kw">c</span>(100L), <span class="dt">name =</span> <span class="st">&quot;x&quot;</span>)
dgauss &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">gradients</span>(<span class="kw">gaussian</span>(x, mu, sig), x)

<span class="kw">with</span>(tf<span class="op">$</span><span class="kw">Session</span>() <span class="op">%as%</span><span class="st"> </span>sess, {
  result &lt;-<span class="st"> </span>sess<span class="op">$</span><span class="kw">run</span>(dgauss, <span class="dt">feed_dict=</span><span class="kw">dict</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">length.out =</span> <span class="dv">100</span>)))
  writer &lt;-<span class="st"> </span>tf<span class="op">$</span>summary<span class="op">$</span><span class="kw">FileWriter</span>(<span class="st">&quot;dgauss_log_summary&quot;</span>, sess<span class="op">$</span>graph)
  <span class="kw">print</span>(result)
})


<span class="kw">tensorboard</span>(<span class="dt">log_dir =</span> <span class="st">&quot;dgauss_log_summary&quot;</span>)</code></pre></div>
<div class="figure">
<img src="img/tensorboard.png" alt="Caption" />
<p class="caption">Caption</p>
</div>
</div>
</div>
<div id="un-exemple-en-python-avec-jupyter-lab" class="section level2">
<h2>Un exemple en python avec Jupyter lab</h2>
<p><a href="https://github.com/StateOfTheR/finistR2018/blob/master/atelier2/TensorFlow/TF_diabetes.ipynb">Python notebook - régression linéaire appris par descente de gradient stochastique</a></p>
<!-- ### Remarques  -->
<!-- Ce que j'aurais voulu faire en plus : récupérer juste la valeur du gradient en un $x$ donné :  -->
<!-- ```{r, echo=TRUE, eval = FALSE} -->
<!-- var_grad <- tf$gradients(gamma.func.tf, x) -->
<!-- var_grad_val <- sess$run(var_grad,feed_dict = dict(x=1,convert=TRUE))  -->
<!-- ``` -->
<!-- Faisable sous python mais pas réussi sous R?  -->
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
